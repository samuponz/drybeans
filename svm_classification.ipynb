{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dry Beans\n",
    "Regarding Pre-Processing, it is necessary to select:\n",
    " - the best scaling strategy, necessary pre-processing step for the SVM classifier;\n",
    " - the best feature selection/feature extraction method. Try with:\n",
    "    - PCA (feature extraction for dimensionality reduction);\n",
    "    - Filter methods such as SelectKBest, SelectPercentile. The metric to use should be the f_classif (ANOVA correlation since attributes are numerical and targets are categorical).\n",
    "- the best way to balance out the classes:\n",
    "    - Oversampling;\n",
    "    - Undersampling;\n",
    "    - built-in methods used by SVC class.\n",
    "- the best way to remove the outliers.\n",
    "    \n",
    "Regarding the classification, it is necessary to select:\n",
    " - the kernel function of the SVM (linear, polynomial, rbf, sigmoid) and the respective parameters (e.g. gamma for the rbf);\n",
    " - the regulatization parameter;\n",
    " - the multiclassification method (ovo or ova);\n",
    " \n",
    " Regarding the training procedure, it is necessary to select:\n",
    "  - the best train\\test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pandas._libs import json\n",
    "import sklearn.decomposition as dec\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, plot_confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as met\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balancing(X_train, y_train, method):\n",
    "    \n",
    "    if method == 'smote':\n",
    "        sampler = SMOTE()\n",
    "    elif method == 'adasyn':\n",
    "        sampler = ADASYN()\n",
    "    elif method == 'smote_tomek':\n",
    "        sampler = SMOTETomek()\n",
    "    elif method == 'smote_enn':\n",
    "        sampler = SMOTEENN()\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_train_resampled, y_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_classification(df):\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size=0.3, random_state=0)\n",
    "    df_traindata, df_trainlabel = df_train.iloc[:, 0:len(df_train.columns) - 1], df_train.iloc[:, -1]\n",
    "    df_testdata, df_testlabel = df_test.iloc[:, 0:len(df_test.columns) - 1], df_test.iloc[:, -1]\n",
    "\n",
    "    warnings.filterwarnings('ignore')\n",
    "    # Baseline - comparing model accuracy using all features across classifiers\n",
    "    classifiers = [\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        KNeighborsClassifier(),\n",
    "        SVC(),\n",
    "        GaussianNB(),\n",
    "        LogisticRegression(),\n",
    "        MLPClassifier()\n",
    "    ]\n",
    "\n",
    "    # Naive Train Accuracy\n",
    "    algo = ['DTC', 'RFC', 'KNN', 'SVC', 'GNB', 'LR', 'MLP']\n",
    "    # algo = []\n",
    "    scores = []\n",
    "    for clf in classifiers:\n",
    "        # algo.append(clf.__class__.__name__)\n",
    "        scores.append(cross_val_score(clf, df_traindata, df_trainlabel, cv=5).mean())\n",
    "    warnings.filterwarnings('ignore')\n",
    "    Naivescore_df_Train = pd.DataFrame({'Algorithm': algo, 'Score': scores}).set_index('Algorithm')\n",
    "\n",
    "    # Naive Test Accuracy\n",
    "    algo = ['DTC', 'RFC', 'KNN', 'SVC', 'GNB', 'LR', 'MLP']\n",
    "    # algo = []\n",
    "    scores = []\n",
    "\n",
    "    for clf in classifiers:\n",
    "        clf = clf.fit(df_traindata, df_trainlabel)\n",
    "        y_pred = clf.predict(df_testdata)\n",
    "        # algo.append(clf.__class__.__name__)\n",
    "        scores.append(accuracy_score(y_pred, df_testlabel))\n",
    "    warnings.filterwarnings('ignore')\n",
    "    Naivescore_df_Test = pd.DataFrame({'Algorithm': algo, 'Score': scores}).set_index('Algorithm')\n",
    "\n",
    "    # Bar plot between Train and Test Accuracy\n",
    "    fig = plt.figure(figsize=(5, 5))  # Create matplotlib figure\n",
    "\n",
    "    ax = fig.add_subplot(111)  # Create matplotlib axes\n",
    "    ax2 = ax.twinx()  # Create another axes that shares the same x-axis as a\n",
    "    width = .3\n",
    "\n",
    "    Naivescore_df_Train.Score.plot(kind='bar', color='green', ax=ax, width=width, position=0)\n",
    "    Naivescore_df_Test.Score.plot(kind='bar', color='red', ax=ax2, width=width, position=1)\n",
    "\n",
    "    ax.grid(None, axis='y')\n",
    "    ax2.grid(None)\n",
    "\n",
    "    ax.set_ylabel('Train')\n",
    "    ax2.set_ylabel('Test')\n",
    "\n",
    "    ax.set_xlim(-1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_grid_search(X_train, X_test, y_train, y_test, scores, model_name, model, model_parameters_grid, n_cv = 5):\n",
    "    \n",
    "    # Creates a pipeline with the selected method\n",
    "    pipe = Pipeline([['over', SMOTE()], [model_name, model]])  # [None, SMOTE(), ADASYN(), SMOTETomek(), SMOTEENN()]\n",
    "    \n",
    "    # Creates an empty dictionary with best parameters for every scoring parameter considered\n",
    "    best_parameters = {key: None for key in scores}\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(24,20), dpi=100, squeeze=False)\n",
    "    fig.suptitle(\"Hyperparameters selection results: \" + model_name.upper(), fontsize=28)\n",
    "\n",
    "    print(\"\\n================================================================================================================================================================\\n\")\n",
    "    print(\"GRID SEARCH FOR \" + model_name.upper() + ':')\n",
    "\n",
    "    # Cross-validation **for every score!**\n",
    "    for score, ax in zip(scores, ax.reshape(-1)):\n",
    "\n",
    "        print(\"\\n ---> Tuning \" + model_name.upper() + \" hyper-parameters for %s\" % score.upper() + \": \")\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(\n",
    "            estimator = pipe,\n",
    "            param_grid = model_parameters_grid,\n",
    "            scoring = score,\n",
    "            n_jobs = -1,\n",
    "            verbose = 4,\n",
    "            return_train_score = True,\n",
    "            cv = n_cv\n",
    "            )\n",
    "\n",
    "        # ignore divide-by-zero warnings, these occur inevitably in the parameter estimation phase and are annoying\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(action=\"ignore\", category=UndefinedMetricWarning)\n",
    "            # .. your divide-by-zero code ..\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "        # PLOTTING CROSS VALIDATION RESULTS:\n",
    "\n",
    "        print(\"\\n ---> Grid scores on development set:\\n\")\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"     ---> %r: %0.3f (+/-%0.03f) for %r\" % (score, mean, std * 2, params))\n",
    "\n",
    "        # FINAL CLASSIFICATION ON TEST SET WITH BEST PARAMETERS (THAT MAXIMISE THE CURRENT SCORE)\n",
    "        \n",
    "        print(\"\\n ---> CLASSIFICATION ON THE TEST SET - Detailed classification report:\")\n",
    "        print(\"     --- The model is trained on the full development set.\")\n",
    "        print(\"     --- The scores are computed on the full evaluation set.\\n\")\n",
    "        \n",
    "        # PLOT RESULTS\n",
    "\n",
    "        # ignore divide-by-zero warnings, these occur inevitably in the parameter estimation phase and are annoying\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(action=\"ignore\", category=UndefinedMetricWarning)\n",
    "            # .. your divide-by-zero code ..\n",
    "            y_true, y_pred = y_test, clf.predict(X_test)\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "\n",
    "        print(\"\\n ---> BEST PARAMETERS SET found on development set:\\n\")\n",
    "        print(clf.best_params_)\n",
    "        best_parameters[score] = clf.best_params_\n",
    "\n",
    "        print(\"\\n------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\")\n",
    "        \n",
    "        # PLOT CONFUSION MATRIX\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "        sns.heatmap(cm, annot=True, fmt='.2%', cmap='icefire', ax=ax)\n",
    "        ax.set_title('Grid search results obtained trying to maximise for: ' + score.upper())\n",
    "\n",
    "        # set x-axis label and ticks. \n",
    "        ax.set_xlabel(\"Predicted Class\", fontsize=14)\n",
    "        ax.xaxis.set_ticklabels(['BARBUNYA', 'BOMBAY', 'CALI', 'DERMASON', 'HOROZ', 'SEKER', 'SIRA'])\n",
    "\n",
    "        # set y-axis label and ticks\n",
    "        ax.set_ylabel(\"Actual Class\", fontsize=14)\n",
    "        ax.yaxis.set_ticklabels(['BARBUNYA', 'BOMBAY', 'CALI', 'DERMASON', 'HOROZ', 'SEKER', 'SIRA'])\n",
    "\n",
    "        \n",
    "    return best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_final_traintest(pipe, X_train, X_test, y_train, y_test, best_parameters, selected_score):\n",
    "    \n",
    "    # Print the best parameters configurations that maximise specific metric/scores\n",
    "    print(\"List of the parameters used according to a specific scoring parameter:\")\n",
    "    print(json.dumps(best_parameters, indent=4))\n",
    "    print()\n",
    "\n",
    "    # # Add a specific parameter to the configuration in order to show iterations\n",
    "    # for i in best_parameters:\n",
    "    #     best_parameters[i]['verbose'] = 0\n",
    "    #     # More info on the 'verbose' parameter:\n",
    "    #     # The verbosity level: if non zero, progress messages are printed. Above 50, the output is sent to stdout.\n",
    "    #     # The frequency of the messages increases with the verbosity level. If it more than 10, all iterations are\n",
    "    #     # reported.\n",
    "    #     # verbose: 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "\n",
    "    # Final classification with optimized parameters:\n",
    "    print(\"Classification:\")\n",
    "    print(\"Parameters set in order to maximise the %s scoring parameter\" % selected_score.upper())\n",
    "\n",
    "    # Instantiate a new classifier object with best parameters for a selected scoring parameter\n",
    "    clf = pipe\n",
    "    clf.set_params(**best_parameters[selected_score])\n",
    "    # Alternative: creating a new classifier object with manually selected parameters, not optimized\n",
    "    # clf = SVC(kernel='rbf', decision_function_shape='ovo', verbose=2)\n",
    "\n",
    "    # Model training:\n",
    "    print(\"Model training:\")\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(action=\"ignore\", category=UndefinedMetricWarning)\n",
    "        # .. your divide-by-zero code ..\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "    # Model testing:\n",
    "    print(\"\\n\\nMaking predictions:\")\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(action=\"ignore\", category=UndefinedMetricWarning)\n",
    "        # .. your divide-by-zero code ..\n",
    "        y_predicted = clf.predict(X_test)\n",
    "\n",
    "        # Performance evaluation\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, y_predicted))\n",
    "        print()\n",
    "\n",
    "        print(classification_report(y_test, y_predicted))\n",
    "        print()\n",
    "\n",
    "    \n",
    "    # PLOT CONFUSION MATRIX\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10))  # figure size is given as a (width, height) tuple\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    cm = confusion_matrix(y_test, y_predicted, normalize='true')\n",
    "    sns.heatmap(cm, annot=True, fmt='.2%', cmap='icefire', ax=ax1)\n",
    "    ax1.set_title('Result obtained with parameters maxmimizing: ' + selected_score.upper())\n",
    "\n",
    "    # set x-axis label and ticks. \n",
    "    ax1.set_xlabel(\"Predicted Class\", fontsize=14)\n",
    "    ax1.xaxis.set_ticklabels(['BARBUNYA', 'BOMBAY', 'CALI', 'DERMASON', 'HOROZ', 'SEKER', 'SIRA'])\n",
    "\n",
    "    # set y-axis label and ticks\n",
    "    ax1.set_ylabel(\"Actual Class\", fontsize=14)\n",
    "    ax1.yaxis.set_ticklabels(['BARBUNYA', 'BOMBAY', 'CALI', 'DERMASON', 'HOROZ', 'SEKER', 'SIRA'])\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df = pd.read_excel(\"DryBeanDataset/Dry_Bean_Dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.tolist()[:-1]]\n",
    "y = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features\n",
    "# X = MinMaxScaler().fit_transform(X)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. \n",
    "# The input data is centered but not scaled for each feature before applying the SVD.\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "pca_df = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16'])\n",
    "\n",
    "pca_df = pd.concat([pca_df, df[['Class']]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "**ATTENTION**: Class Balancing cannot be done a priori since we perform K-Fold Cross Validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive_classification(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter selection (grid search and k-fold cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameter optimization using k-fold cross validation: estimation of the classifier's parameters that maximise specific metrics/scores\n",
    "\n",
    "models = {\n",
    "    # \"Random_Forest\": RandomForestClassifier(\n",
    "    #     min_samples_leaf=1, max_depth = None, bootstrap = True, \n",
    "    #     oob_score = False, min_samples_split = 2,\n",
    "    #     ),\n",
    "    # \"Extra_Trees\": ExtraTreesClassifier(\n",
    "    #     min_samples_leaf=1, max_depth = None, bootstrap = False, \n",
    "    #     oob_score = False, min_samples_split = 2,\n",
    "    #     ),\n",
    "    # \"KNN\": KNeighborsClassifier(\n",
    "    #     ),\n",
    "    # \"SVM\": SVC(\n",
    "    #     ),\n",
    "    \"MLP\": MLPClassifier( \n",
    "        alpha=1e-5, \n",
    "        learning_rate='constant',\n",
    "        max_iter=1000,\n",
    "        tol=1e-4,\n",
    "        verbose=False,\n",
    "        momentum=0.9,\n",
    "        early_stopping=False,\n",
    "        )\n",
    "}\n",
    "\n",
    "# Set the parameters by cross-validation for different models\n",
    "models_parameters_grids = {\n",
    "    # \"Random_Forest\":\n",
    "    #     {\n",
    "    #         \"Random_Forest__n_estimators\": [256], \n",
    "    #         \"Random_Forest__criterion\": [\"gini\"],                    # {\"gini\", \"entropy\", \"log_loss\"}\n",
    "    #         \"Random_Forest__max_features\": [\"sqrt\"],                 # {\"sqrt\", \"log2\", None}\n",
    "    #     },\n",
    "    # \"Extra_Trees\":   \n",
    "    #     {\n",
    "    #         \"Extra_Trees__n_estimators\":  [32], \n",
    "    #         \"Extra_Trees__criterion\": [\"gini\"],                    # {\"gini\", \"entropy\", \"log_loss\"}\n",
    "    #         \"Extra_Trees__max_features\": [\"sqrt\"],                 # {\"sqrt\", \"log2\", None}\n",
    "    #     },\n",
    "    # \"KNN\": \n",
    "    #     {\n",
    "    #         'KNN__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    #         'KNN__n_neighbors': [5, 10, 15],\n",
    "    #     },\n",
    "    # \"SVM\": \n",
    "    #     [\n",
    "    #         {\n",
    "    #             'SVM__kernel': ['rbf'],\n",
    "    #             'SVM__gamma': [0.05, 0.1],\n",
    "    #             'SVM__C': [100],\n",
    "    #             'SVM__decision_function_shape': ['ovo'],  # by default this is set to ovr\n",
    "    #         },   \n",
    "    \n",
    "    #         {   \n",
    "    #             'SVM__kernel': ['linear'],\n",
    "    #             'SVM__C': [1, 10, 100, 1000],\n",
    "    #             'SVM__decision_function_shape': ['ovo'],\n",
    "    #         }\n",
    "    #     ],\n",
    "    \"MLP\":\n",
    "            {\n",
    "                'MLP__activation': ['identity', 'logistic', 'tanh', 'relu'],    # {identity', 'logistic', 'tanh', 'relu'}\n",
    "                'MLP__solver': ['adam',],     # {'lbfgs', 'sgd', 'adam'}\n",
    "                'MLP__hidden_layer_sizes': [(12, 3), (16, 16), (256, 256), (16, 16, 16, 16)], \n",
    "                'MLP__learning_rate_init': [0.3, 0.1, 0.01],\n",
    "            }\n",
    "}\n",
    "\n",
    "# Choose the metrics to optimize for\n",
    "# scores = ['accuracy']\n",
    "scores = ['accuracy']\n",
    "\n",
    "model_results  = {\n",
    "    # \"Random_Forest\": {},\n",
    "    # \"Extra_Trees\": {},\n",
    "    # \"KNN\": {},\n",
    "    # \"SVM\": {},\n",
    "    \"MLP\": {}\n",
    "}\n",
    "\n",
    "for model_name in models:\n",
    "# Create pipeline\n",
    "    model_best_parameters = model_grid_search(X_train, X_test, y_train, y_test, scores, model_name, models.get(model_name), models_parameters_grids.get(model_name), n_cv=5)\n",
    "    model_results[model_name] = model_best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLP': {'accuracy': {'MLP__activation': 'logistic',\n",
       "   'MLP__hidden_layer_sizes': (16, 16),\n",
       "   'MLP__learning_rate_init': 0.01,\n",
       "   'MLP__solver': 'adam'}}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final classification\n",
    "\n",
    "# selection of a particular configuration: this is done selecting the relative metric\n",
    "selected_score = \"accuracy\"\n",
    "\n",
    "best_parameters = \n",
    "\n",
    "svm_clf = pipeline_final_traintest(pipe, X_train, X_test, y_train, y_test, best_parameters, selected_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Create a feature-selection transform, a scaler and an instance of SVM that we\n",
    "# # combine together to have a full-blown estimator\n",
    "\n",
    "# clf = Pipeline(\n",
    "#     [\n",
    "#         (\"anova\", SelectPercentile(f_classif)), # Metric is ANOVA\n",
    "#         (\"scaler\", MinMaxScaler()),\n",
    "#         (\"svc\", SVC(gamma=\"auto\")),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This takes 2 minutes\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# score_means = list()\n",
    "# score_stds = list()\n",
    "# percentiles = (1, 3, 6, 10, 15, 20, 30, 40, 60, 80, 100)\n",
    "\n",
    "# for percentile in percentiles:\n",
    "#     clf.set_params(anova__percentile=percentile)\n",
    "#     this_scores = cross_val_score(clf, X, y)\n",
    "#     score_means.append(this_scores.mean())\n",
    "#     score_stds.append(this_scores.std())\n",
    "\n",
    "# plt.errorbar(percentiles, score_means, np.array(score_stds))\n",
    "# plt.title(\"Performance of the SVM-Anova varying the percentile of features selected\")\n",
    "# plt.xticks(np.linspace(0, 100, 11, endpoint=True))\n",
    "# plt.xlabel(\"Percentile\")\n",
    "# plt.ylabel(\"Accuracy Score\")\n",
    "# plt.axis(\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
